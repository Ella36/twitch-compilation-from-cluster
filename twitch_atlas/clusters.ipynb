{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "import json\n",
    "\n",
    "from jq import jq\n",
    "import tomlkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = tomlkit.document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to document\n",
    "def add_cluster_to_doc(cluster, doc):\n",
    "    \"\"\"\n",
    "    Add a cluster to a toml doc\n",
    "    \"\"\"\n",
    "    tab = tomlkit.table()\n",
    "    a = tomlkit.array(cluster[\"creators\"]).multiline(True)\n",
    "    tab.add(\"creators\", a)\n",
    "    doc[cluster[\"name\"]] = tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give cluster related to creators\n",
    "Algorithms:\n",
    "1. 'edge'\n",
    "2. 'color'\n",
    "3. 'xy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge\n",
    "def create_cluster_from_large_edges(creator: str, limit=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    5 relevant creators that are connected\n",
    "    \"\"\"\n",
    "    edges = f'. as $parent | $parent.nodes[] | select(.label==\"{creator}\") | .id as $source | [$parent.edges[] | select(.source == $source)] | sort_by(.size) | reverse | map(.target) | .[0:{limit}][] as $target | $parent.nodes[] | select(.id == $target) | .label'\n",
    "    creators = jq(edges).input_value(data).all()\n",
    "    return creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color\n",
    "def create_cluster_from_color(creator: str, limit=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    5 relevant creators in the same group\n",
    "    \"\"\"\n",
    "    color = f'. as $parent | $parent.nodes[] | select(.label==\"{creator}\") | .attributes.\"Modularity Class\" as $mod | [$parent.nodes[] | select(.attributes.\"Modularity Class\"==$mod) ] | sort_by(.size) | reverse | .[0:{limit}][] | .label'\n",
    "    creators = jq(color).input_value(data).all()\n",
    "    return creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xy\n",
    "def create_cluster_from_xy(creator: str, limit=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    5 relevant creators in the same area\n",
    "    \"\"\"\n",
    "    xy = '[. as $parent | $parent.nodes[] | select(.label==\"'+creator+'\") | . as {$id, $x, $y} | $parent.edges[] | select(.source == $id) | .target as $target | $parent.nodes[] | select(.id == $target) | .dy = ($y-.y)*($y-.y) | .dx = ($x-.x)*($x-.x) | .d = .dx + .dy] | sort_by(.d) | map(.label) | .[0:'+str(limit)+'][]'\n",
    "    creators = jq(xy).input_value(data).all()\n",
    "    return creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_func: dict[str, Callable] = {\n",
    "  'edge': create_cluster_from_large_edges,\n",
    "  'color': create_cluster_from_color,\n",
    "  'xy': create_cluster_from_xy,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = tomlkit.parse(\"\"\"[test]\n",
    "    algo=\"xy\"\n",
    "    max=15\n",
    "    creators = [\"shroud\", \"VALORANT\"]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.toml\", \"r\") as f:\n",
    "    doc = tomlkit.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['Nmplol', 'xQcOW', 'HasanAbi', 'moistcr1tikal', 'EsfandTV', 'ludwig', 'GMHikaru', 'sodapoppin', 'Mizkif', 'Trainwreckstv', '39daph', 'QTCinderella', 'pokelawls', 'SmallAnt', 'forsen']\n",
      "13\n",
      "['ImKaiCenat', 'SypherPK', 'Clix', 'Bugha', 'AdinRoss', 'benjyfishy', 'BLOU', 'ops1x', 'yourragegaming', 'LosPollosTV', 'Fortnite', 'Tyceno', 'Mongraal']\n",
      "15\n",
      "['QuarterJade', 'pokimane', 'fuslie', 'ironmouse', 'lilypichu', 'Tectone', 'CDawgVA', 'boxbox', 'nyanners', 'Sykkuno', 'Natsumiii', 'veibae', 'TinaKitten', 'Scarra', 'Enviosity']\n",
      "5\n",
      "['TheStockGuy', 'Xaryu', 'nyanners', 'AdmiralBulldog', 'CDNThe3rd']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "clusters_to_update = [\n",
    "    \"offlinetv\",\n",
    "    \"orange\",\n",
    "    \"fortnite\",\n",
    "]\n",
    "\n",
    "# Extend clusters based on chosen algo\n",
    "for name, info in doc.items():\n",
    "    if name not in clusters_to_update:\n",
    "        continue\n",
    "    new_candidates = []\n",
    "    for creator in info[\"creators\"]:\n",
    "        new_creators = string_to_func[info[\"algo\"]](creator, limit=100)\n",
    "        new_candidates.extend(new_creators)\n",
    "    new_candidates = set(new_candidates)\n",
    "    n_creators = len(info[\"creators\"])\n",
    "    n_max = info[\"max\"]\n",
    "    if n_creators >= n_max:\n",
    "        continue\n",
    "    n_to_add = min(n_max - n_creators, len(new_candidates))\n",
    "    print(n_to_add)\n",
    "    new_creators = random.sample(list(new_candidates), k=n_to_add)\n",
    "    creators = info[\"creators\"]\n",
    "    creators.extend(new_creators)\n",
    "    creators = list(set(creators)) # remove duplicates\n",
    "    creators = sorted(creators, key=lambda L: (L.lower(), L)) #  sort case-insensitive)\n",
    "    info[\"creators\"] = tomlkit.array(creators).multiline(True)\n",
    "    print(new_creators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save doc to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clusters.toml\", \"w\") as f:\n",
    "    tomlkit.dump(doc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
