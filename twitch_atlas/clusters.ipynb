{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "import json\n",
    "\n",
    "from jq import jq\n",
    "import tomlkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = tomlkit.document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to document\n",
    "def add_cluster_to_doc(cluster, doc):\n",
    "    \"\"\"\n",
    "    Add a cluster to a toml doc\n",
    "    \"\"\"\n",
    "    tab = tomlkit.table()\n",
    "    a = tomlkit.array(cluster[\"creators\"]).multiline(True)\n",
    "    tab.add(\"creators\", a)\n",
    "    doc[cluster[\"name\"]] = tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give cluster related to creators\n",
    "Algorithms:\n",
    "1. 'edge'\n",
    "2. 'color'\n",
    "3. 'xy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge\n",
    "def create_cluster_from_large_edges(creator: str, limit=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    5 relevant creators that are connected\n",
    "    \"\"\"\n",
    "    edges = f'. as $parent | $parent.nodes[] | select(.label==\"{creator}\") | .id as $source | [$parent.edges[] | select(.source == $source)] | sort_by(.size) | reverse | map(.target) | .[0:{limit}][] as $target | $parent.nodes[] | select(.id == $target) | .label'\n",
    "    creators = jq(edges).input_value(data).all()\n",
    "    return creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color\n",
    "def create_cluster_from_color(creator: str, limit=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    5 relevant creators in the same group\n",
    "    \"\"\"\n",
    "    color = f'. as $parent | $parent.nodes[] | select(.label==\"{creator}\") | .attributes.\"Modularity Class\" as $mod | [$parent.nodes[] | select(.attributes.\"Modularity Class\"==$mod) ] | sort_by(.size) | reverse | .[0:{limit}][] | .label'\n",
    "    creators = jq(color).input_value(data).all()\n",
    "    return creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xy\n",
    "def create_cluster_from_xy(creator: str, limit=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    5 relevant creators in the same area\n",
    "    \"\"\"\n",
    "    xy = '[. as $parent | $parent.nodes[] | select(.label==\"'+creator+'\") | . as {$id, $x, $y} | $parent.edges[] | select(.source == $id) | .target as $target | $parent.nodes[] | select(.id == $target) | .dy = ($y-.y)*($y-.y) | .dx = ($x-.x)*($x-.x) | .d = .dx + .dy] | sort_by(.d) | map(.label) | .[0:'+str(limit)+'][]'\n",
    "    creators = jq(xy).input_value(data).all()\n",
    "    return creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_func: dict[str, Callable] = {\n",
    "  'edge': create_cluster_from_large_edges,\n",
    "  'color': create_cluster_from_color,\n",
    "  'xy': create_cluster_from_xy,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = tomlkit.parse(\"\"\"[test]\n",
    "    algo=\"xy\"\n",
    "    max=15\n",
    "    creators = [\"shroud\", \"VALORANT\"]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.toml\", \"r\") as f:\n",
    "    doc = tomlkit.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgreen\n",
      "\t1\n",
      "\t['Destroy']\n",
      "purple\n",
      "\t2\n",
      "\t['CathFawr', 'Kyle']\n",
      "cyan\n",
      "\t3\n",
      "\t['Strippin', 'Calebhart42', 'Fairlight_Excalibur']\n",
      "yellow\n",
      "\t13\n",
      "\t['hc_diZee', 'Vlesk', 'GRONKH', 'unsympathisch_tv', 'Kamikatze', 'TheRealKnossi', 'ClassyBeef', 'PokerStars247', 'maxim', 'chefstrobel', 'DerHauge', 'H0llyLP', 'BeamTwitch']\n",
      "orange\n",
      "\t4\n",
      "\t['TimTheTatman', 'Maya', 'roflgator', 'Hungrybox']\n",
      "giants\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Update all or only selected clusters\n",
    "is_update_all = True\n",
    "clusters_to_update = [\n",
    "    \"offlinetv\",\n",
    "    \"orange\",\n",
    "    \"fortnite\",\n",
    "]\n",
    "\n",
    "# Extend clusters based on chosen algo\n",
    "for name, info in doc.items():\n",
    "    print(name)\n",
    "    if not is_update_all and name not in clusters_to_update:\n",
    "        continue\n",
    "    new_candidates = []\n",
    "    for creator in info[\"creators\"]:\n",
    "        new_creators = string_to_func[info[\"algo\"]](creator, limit=100)\n",
    "        new_candidates.extend(new_creators)\n",
    "    new_candidates = set(new_candidates)\n",
    "    n_creators = len(info[\"creators\"])\n",
    "    n_max = info[\"max\"]\n",
    "    if n_creators >= n_max:\n",
    "        continue\n",
    "    n_to_add = min(n_max - n_creators, len(new_candidates))\n",
    "    print(f\"\\t{n_to_add}\")\n",
    "    new_creators = random.sample(list(new_candidates), k=n_to_add)\n",
    "    creators = info[\"creators\"]\n",
    "    creators.extend(new_creators)\n",
    "    creators = list(set(creators)) # remove duplicates\n",
    "    creators = sorted(creators, key=lambda L: (L.lower(), L)) #  sort case-insensitive)\n",
    "    info[\"creators\"] = tomlkit.array(creators).multiline(True)\n",
    "    print(\"\\t\"+str(new_creators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save doc to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clusters.toml\", \"w\") as f:\n",
    "    tomlkit.dump(doc, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
